{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = 'data/DSL-TRAIN.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252000\n"
     ]
    }
   ],
   "source": [
    "# First let's see how many examples we have to work with\n",
    "linecount = 0\n",
    "with open(dataset, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        linecount += 1\n",
    "print(linecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's briefly examine two tokenizing methods, the treebank tokenizer and a simple RegEx based tokenizer\n",
    "with open(dataset, encoding='utf-8') as f:\n",
    "    text, lang = f.readline().split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '57,5',\n",
       " 'miliona',\n",
       " 'maloljetnih',\n",
       " 'djevojčica',\n",
       " 'prisilno',\n",
       " 'stupi',\n",
       " 'u',\n",
       " 'brak',\n",
       " 'širom',\n",
       " 'svijeta',\n",
       " ',',\n",
       " 'dok',\n",
       " 'čak',\n",
       " '40',\n",
       " 'odsto',\n",
       " 'od',\n",
       " 'tog',\n",
       " 'broja',\n",
       " 'čine',\n",
       " 'maloljetne',\n",
       " 'Indijke',\n",
       " '.']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TreebankWordTokenizer().tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '57',\n",
       " ',5',\n",
       " 'miliona',\n",
       " 'maloljetnih',\n",
       " 'djevojčica',\n",
       " 'prisilno',\n",
       " 'stupi',\n",
       " 'u',\n",
       " 'brak',\n",
       " 'širom',\n",
       " 'svijeta',\n",
       " ',',\n",
       " 'dok',\n",
       " 'čak',\n",
       " '40',\n",
       " 'odsto',\n",
       " 'od',\n",
       " 'tog',\n",
       " 'broja',\n",
       " 'čine',\n",
       " 'maloljetne',\n",
       " 'Indijke',\n",
       " '.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\S+')\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "columns = ['Text', 'Language']\n",
    "df_dataset = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n"
     ]
    }
   ],
   "source": [
    "# Now load the tokenized examples into the DataFrame\n",
    "with open(dataset, encoding='utf-8') as f:\n",
    "    for i in range(252000):\n",
    "        text, lang = f.readline().split('\\t')\n",
    "        df_dataset.loc[i] = [text, lang[:-1]]\n",
    "        if i % 10000 == 0:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dataset.loc[251999]['Language']='sr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bs',\n",
       " 'es-AR',\n",
       " 'es-ES',\n",
       " 'es-PE',\n",
       " 'fa-AF',\n",
       " 'fa-IR',\n",
       " 'fr-CA',\n",
       " 'fr-FR',\n",
       " 'hr',\n",
       " 'id',\n",
       " 'my',\n",
       " 'pt-BR',\n",
       " 'pt-PT',\n",
       " 'sr']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_dataset.Language.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgDict = {'bs': 'Bosnian',\n",
    " 'es-AR': 'Spanish-Argentine',\n",
    " 'es-ES': 'Spanish-Spanish',\n",
    " 'es-PE': 'Spanish-Peruvian',\n",
    " 'fa-AF': 'Farsi-Dari',\n",
    " 'fa-IR': 'Farsi-Persian',\n",
    " 'fr-CA': 'French-Canadian',\n",
    " 'fr-FR': 'French-French',\n",
    " 'hr': 'Croatian',\n",
    " 'id': 'Bahasa-Indonesian',\n",
    " 'my': 'Bahasa-Malaysian',\n",
    " 'pt-BR': 'Portuguese-Brazilian',\n",
    " 'pt-PT': 'Portuguese-Portuguese',\n",
    " 'sr': 'Serbian'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/languages.txt', 'w') as lgfile:\n",
    "    lgfile.write(str(list(df_dataset.Language.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- 57,5 miliona',\n",
       " '57,5 miliona maloljetnih',\n",
       " 'miliona maloljetnih djevojčica',\n",
       " 'maloljetnih djevojčica prisilno',\n",
       " 'djevojčica prisilno stupi',\n",
       " 'prisilno stupi u',\n",
       " 'stupi u brak',\n",
       " 'u brak širom',\n",
       " 'brak širom svijeta',\n",
       " 'širom svijeta ,',\n",
       " 'svijeta , dok',\n",
       " ', dok čak',\n",
       " 'dok čak 40',\n",
       " 'čak 40 odsto',\n",
       " '40 odsto od',\n",
       " 'odsto od tog',\n",
       " 'od tog broja',\n",
       " 'tog broja čine',\n",
       " 'broja čine maloljetne',\n",
       " 'čine maloljetne Indijke',\n",
       " 'maloljetne Indijke .']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng = ngrams(tokens, 3)\n",
    "[\" \".join(x) for x in ng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bahasa', 'Indonesian']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgDict['id'].split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FRIDAY\\Anaconda3\\envs\\spacy\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\FRIDAY\\Anaconda3\\envs\\spacy\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\FRIDAY\\Anaconda3\\envs\\spacy\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\FRIDAY\\Anaconda3\\envs\\spacy\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\FRIDAY\\Anaconda3\\envs\\spacy\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "lgs = list(df_dataset.Language.unique())\n",
    "for lg in lgs:\n",
    "    df2 = df_dataset[(df_dataset['Language']==lg)]\n",
    "    df2['Code'] = df2['Language']\n",
    "    if '-' not in lg:\n",
    "        df2['Language'] = [lgDict[lg] for i in range(df2.shape[0])]\n",
    "        df2['Dialect'] = [lgDict[lg] for i in range(df2.shape[0])]\n",
    "    else:\n",
    "        df2['Language'] = [lgDict[lg].split('-')[0] for i in range(df2.shape[0])]\n",
    "        df2['Dialect'] = [lgDict[lg].split('-')[1] for i in range(df2.shape[0])]\n",
    "    filename = \"data/dataset-{}.csv\".format(lg)\n",
    "    df2.to_csv(filename, encoding=\"utf-16\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df_dataset[(df_dataset['Language']=='fa-IR')]\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FRIDAY\\Anaconda3\\envs\\spacy\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3['Code'] = df3['Language']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FRIDAY\\Anaconda3\\envs\\spacy\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3['Language'] = [lgDict['hr'] for i in range(df3.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144000</th>\n",
       "      <td>Predstavljene su sjemenske sorte PIONEER, a pr...</td>\n",
       "      <td>Croatian</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144001</th>\n",
       "      <td>Još sam 2003. ili 2004. imao pravo na saborsku...</td>\n",
       "      <td>Croatian</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144002</th>\n",
       "      <td>U utorak su pretraženi stanovi i druge prostor...</td>\n",
       "      <td>Croatian</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144003</th>\n",
       "      <td>Više od 5200 osoba pobjeglo je iz okolice vulk...</td>\n",
       "      <td>Croatian</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144004</th>\n",
       "      <td>Samsung je redizajnirao TV zaslon tako što je ...</td>\n",
       "      <td>Croatian</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Language Code\n",
       "144000  Predstavljene su sjemenske sorte PIONEER, a pr...  Croatian   hr\n",
       "144001  Još sam 2003. ili 2004. imao pravo na saborsku...  Croatian   hr\n",
       "144002  U utorak su pretraženi stanovi i druge prostor...  Croatian   hr\n",
       "144003  Više od 5200 osoba pobjeglo je iz okolice vulk...  Croatian   hr\n",
       "144004  Samsung je redizajnirao TV zaslon tako što je ...  Croatian   hr"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.to_csv(\"test.csv\", encoding=\"utf-16\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_read= pd.read_csv('data/dataset-fa-IR.csv', encoding=\"utf-16\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Code</th>\n",
       "      <th>Dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>نیروهای نظامی سومالی و اتحادیه آفریقا با بیرون...</td>\n",
       "      <td>Farsi</td>\n",
       "      <td>fa-IR</td>\n",
       "      <td>Persian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>روز دوشنبه، احمد داوود اوغلو وزیر امورخارجه تر...</td>\n",
       "      <td>Farsi</td>\n",
       "      <td>fa-IR</td>\n",
       "      <td>Persian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>فرمامدهی مرکزی آمریکا، که بر عملیات نظامی آمری...</td>\n",
       "      <td>Farsi</td>\n",
       "      <td>fa-IR</td>\n",
       "      <td>Persian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بسیاری از افرادی‌که گفته‌اند دنبال کار نمی‌گرد...</td>\n",
       "      <td>Farsi</td>\n",
       "      <td>fa-IR</td>\n",
       "      <td>Persian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کاخ سفيد نيز در اطلاعيه ای به مردم ايران تسليت...</td>\n",
       "      <td>Farsi</td>\n",
       "      <td>fa-IR</td>\n",
       "      <td>Persian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language   Code  Dialect\n",
       "0  نیروهای نظامی سومالی و اتحادیه آفریقا با بیرون...    Farsi  fa-IR  Persian\n",
       "1  روز دوشنبه، احمد داوود اوغلو وزیر امورخارجه تر...    Farsi  fa-IR  Persian\n",
       "2  فرمامدهی مرکزی آمریکا، که بر عملیات نظامی آمری...    Farsi  fa-IR  Persian\n",
       "3  بسیاری از افرادی‌که گفته‌اند دنبال کار نمی‌گرد...    Farsi  fa-IR  Persian\n",
       "4  کاخ سفيد نيز در اطلاعيه ای به مردم ايران تسليت...    Farsi  fa-IR  Persian"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ن ی ر',\n",
       " 'ی ر و',\n",
       " 'ر و ه',\n",
       " 'و ه ا',\n",
       " 'ه ا ی',\n",
       " 'ا ی  ',\n",
       " 'ی   ن',\n",
       " '  ن ظ',\n",
       " 'ن ظ ا',\n",
       " 'ظ ا م',\n",
       " 'ا م ی',\n",
       " 'م ی  ',\n",
       " 'ی   س',\n",
       " '  س و',\n",
       " 'س و م',\n",
       " 'و م ا',\n",
       " 'م ا ل',\n",
       " 'ا ل ی',\n",
       " 'ل ی  ',\n",
       " 'ی   و',\n",
       " '  و  ',\n",
       " 'و   ا',\n",
       " '  ا ت',\n",
       " 'ا ت ح',\n",
       " 'ت ح ا',\n",
       " 'ح ا د',\n",
       " 'ا د ی',\n",
       " 'د ی ه',\n",
       " 'ی ه  ',\n",
       " 'ه   آ',\n",
       " '  آ ف',\n",
       " 'آ ف ر',\n",
       " 'ف ر ی',\n",
       " 'ر ی ق',\n",
       " 'ی ق ا',\n",
       " 'ق ا  ',\n",
       " 'ا   ب',\n",
       " '  ب ا',\n",
       " 'ب ا  ',\n",
       " 'ا   ب',\n",
       " '  ب ی',\n",
       " 'ب ی ر',\n",
       " 'ی ر و',\n",
       " 'ر و ن',\n",
       " 'و ن  ',\n",
       " 'ن   ر',\n",
       " '  ر ا',\n",
       " 'ر ا ن',\n",
       " 'ا ن د',\n",
       " 'ن د ن',\n",
       " 'د ن \\xa0',\n",
       " 'ن \\xa0  ',\n",
       " '\\xa0   ا',\n",
       " '  ا س',\n",
       " 'ا س ل',\n",
       " 'س ل ا',\n",
       " 'ل ا م',\n",
       " 'ا م گ',\n",
       " 'م گ ر',\n",
       " 'گ ر ا',\n",
       " 'ر ا ی',\n",
       " 'ا ی ا',\n",
       " 'ی ا ن',\n",
       " 'ا ن  ',\n",
       " 'ن   ا',\n",
       " '  ا ل',\n",
       " 'ا ل ش',\n",
       " 'ل ش ب',\n",
       " 'ش ب ا',\n",
       " 'ب ا ب',\n",
       " 'ا ب ،',\n",
       " 'ب ،  ',\n",
       " '،   ک',\n",
       " '  ک ن',\n",
       " 'ک ن ت',\n",
       " 'ن ت ر',\n",
       " 'ت ر ل',\n",
       " 'ر ل  ',\n",
       " 'ل   ش',\n",
       " '  ش م',\n",
       " 'ش م ا',\n",
       " 'م ا ر',\n",
       " 'ا ر ی',\n",
       " 'ر ی  ',\n",
       " 'ی   ا',\n",
       " '  ا ز',\n",
       " 'ا ز  ',\n",
       " 'ز   ش',\n",
       " '  ش ه',\n",
       " 'ش ه ر',\n",
       " 'ه ر ه',\n",
       " 'ر ه ا',\n",
       " 'ه ا ی',\n",
       " 'ا ی  ',\n",
       " 'ی   ج',\n",
       " '  ج ن',\n",
       " 'ج ن و',\n",
       " 'ن و ب',\n",
       " 'و ب ی',\n",
       " 'ب ی  ',\n",
       " 'ی   و',\n",
       " '  و  ',\n",
       " 'و   م',\n",
       " '  م ر',\n",
       " 'م ر ز',\n",
       " 'ر ز ی',\n",
       " 'ز ی  ',\n",
       " 'ی   س',\n",
       " '  س و',\n",
       " 'س و م',\n",
       " 'و م ا',\n",
       " 'م ا ل',\n",
       " 'ا ل ی',\n",
       " 'ل ی  ',\n",
       " 'ی   ر',\n",
       " '  ر ا',\n",
       " 'ر ا  ',\n",
       " 'ا   د',\n",
       " '  د ر',\n",
       " 'د ر  ',\n",
       " 'ر   د',\n",
       " '  د س',\n",
       " 'د س ت',\n",
       " 'س ت  ',\n",
       " 'ت   گ',\n",
       " '  گ ر',\n",
       " 'گ ر ف',\n",
       " 'ر ف ت',\n",
       " 'ف ت ن',\n",
       " 'ت ن د',\n",
       " 'ن د .']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng = ngrams(df_read.loc[0]['Text'], 3)\n",
    "[\" \".join(x) for x in ng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'نیروهای نظامی سومالی و اتحادیه آفریقا با بیرون راندن\\xa0 اسلامگرایان الشباب، کنترل شماری از شهرهای جنوبی و مرزی سومالی را در دست گرفتند.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read.loc[0]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'نیروهای نظامی سومالی و اتحادیه آفریقا با بیرون راندن\\xa0 اسلامگرایان الشباب، کنترل شماری از شهرهای جنوبی و مرزی سومالی را در دست گرفتند.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read.loc[0]['Text']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (spacy)",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "543px",
    "left": "1536px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
